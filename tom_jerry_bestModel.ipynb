{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tom_jerry_bestModel.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/facelesshawk/hello-worldFaceless/blob/master/tom_jerry_bestModel.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "PhH6ifEQt4N5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "from skimage.transform import resize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sJF3geUoDWUN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yxMDZ_q6EH01",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "85ccba62-1bc2-4798-d934-70fb9766286c"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VjGe3y-KEYx9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "c579bef8-412c-466d-837e-8f963e7a77a7"
      },
      "cell_type": "code",
      "source": [
        "cd drive"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rcnwuGPwt4OR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "84f469a4-c644-4934-e452-e32003acb3da"
      },
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "videoFile = \"Tom and jerry.mp4\"\n",
        "cap = cv2.VideoCapture(videoFile)\n",
        "frameRate = cap.get(5) #frame rate\n",
        "x=1\n",
        "while(cap.isOpened()):\n",
        "    frameId = cap.get(1) #current frame number\n",
        "    ret, frame = cap.read()\n",
        "    if (ret != True):\n",
        "        break\n",
        "    if (frameId % math.floor(frameRate) == 0):\n",
        "        filename =\"frame%d.jpg\" % count;count+=1\n",
        "        cv2.imwrite(filename, frame)\n",
        "cap.release()\n",
        "print (\"Done!\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5_pfBwR1t4Of",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "54398266-df5c-4d92-dcef-79f0dae2d87c"
      },
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "videoFile = \"Tom and Jerry 3.mp4\"\n",
        "cap = cv2.VideoCapture(videoFile)\n",
        "frameRate = cap.get(5) #frame rate\n",
        "x=1\n",
        "while(cap.isOpened()):\n",
        "    frameId = cap.get(1) #current frame number\n",
        "    ret, frame = cap.read()\n",
        "    if (ret != True):\n",
        "        break\n",
        "    if (frameId % math.floor(frameRate) == 0):\n",
        "        filename =\"test%d.jpg\" % count;count+=1\n",
        "        cv2.imwrite(filename, frame)\n",
        "cap.release()\n",
        "print (\"Done!\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8Imhx_Nuu3q4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NW-YAsoWt4Op",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# 2. Load a file by ID and create local file.\n",
        "downloaded = drive.CreateFile({'id':'1AI9fNwD5qQ9XcAe3MZP4ycV88c7p2NSk'})\n",
        "# replace fileid with Id of file you want to access\n",
        "downloaded1 = drive.CreateFile({'id':'1zCMfZrgKNtLOHnBZ6MmyRDlM1gSL6yoC'})\n",
        "downloaded.GetContentFile('mapping(1).csv') # now you can use export.csv\n",
        "downloaded1.GetContentFile('testing(1).csv')\n",
        "\n",
        "data = pd.read_csv('mapping(1).csv')\n",
        "test = pd.read_csv('testing(1).csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tMZREnsUt4Ov",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = []\n",
        "for img_name in data.Image_ID:\n",
        "    img = plt.imread('' + img_name)\n",
        "    X.append(img)\n",
        "X = np.array(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7fsre_Vzt4O2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_image = []\n",
        "for img_name in test.Image_ID:\n",
        "    img = plt.imread('' + img_name)\n",
        "    test_image.append(img)\n",
        "test_img = np.array(test_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-2IGQET1t4PB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import np_utils\n",
        "train_y = np_utils.to_categorical(data.Class)\n",
        "test_y = np_utils.to_categorical(test.Class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X5jMKdd8t4PM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "c8efa2a4-855e-4f16-cae2-071e03c90307"
      },
      "cell_type": "code",
      "source": [
        "image = []\n",
        "for i in range(0,X.shape[0]):\n",
        "    a = resize(X[i], preserve_range=True, output_shape=(224,224,3)).astype(int)\n",
        "    image.append(a)\n",
        "X = np.array(image)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
            "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "P8XJSCPft4PZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "503b30fc-166c-43f2-b85f-8f5ec90d6f73"
      },
      "cell_type": "code",
      "source": [
        "test_image = []\n",
        "for i in range(0,test_img.shape[0]):\n",
        "    a = resize(test_img[i], preserve_range=True, output_shape=(224,224)).astype(int)\n",
        "    test_image.append(a)\n",
        "test_image = np.array(test_image)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
            "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "0lqQyHsEt4Po",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import preprocess_input\n",
        "X = X.astype('float32')\n",
        "X = preprocess_input(X)\n",
        "test_image = test_image.astype('float32')\n",
        "test_image = preprocess_input(test_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_CfGlC-Gt4P0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, train_y, test_size=0.3, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GSuYNpHUt4P_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7548
        },
        "outputId": "0d2891c0-4abe-44d1-9ade-7a5246f12cfe"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Dense, InputLayer, Dropout\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "X_train = base_model.predict(X_train)\n",
        "X_valid = base_model.predict(X_valid)\n",
        "test_image = base_model.predict(test_image)\n",
        "X_train = X_train.reshape(208, 7*7*512)\n",
        "X_valid = X_valid.reshape(90, 7*7*512)\n",
        "test_image = test_image.reshape(186, 7*7*512)\n",
        "train = X_train/X_train.max()\n",
        "X_valid = X_valid/X_train.max()\n",
        "test_image = test_image/test_image.max()\n",
        "model = Sequential()\n",
        "model.add(InputLayer((7*7*512,)))    # input layer\n",
        "model.add(Dense(units=1024, activation='sigmoid'))   # hidden layer\n",
        "model.add(Dropout(0.5))      # adding dropout\n",
        "model.add(Dense(units=512, activation='sigmoid'))    # hidden layer\n",
        "model.add(Dropout(0.5))      # adding dropout\n",
        "model.add(Dense(units=256, activation='sigmoid'))    # hidden layer\n",
        "model.add(Dropout(0.5))      # adding dropout\n",
        "model.add(Dense(3, activation='sigmoid'))            # output layer\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "from sklearn.utils.class_weight import compute_class_weight, compute_sample_weight\n",
        "class_weights = compute_class_weight('balanced',np.unique(data.Class), data.Class)  # computing weights of different classes\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "filepath=\"weights.best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]      # model check pointing based on validation loss\n",
        "model.fit(train, y_train, epochs=100,verbose=1, validation_data=(X_valid, y_valid), class_weight=class_weights, callbacks=callbacks_list)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 208 samples, validate on 90 samples\n",
            "Epoch 1/100\n",
            "208/208 [==============================] - 1s 5ms/step - loss: 1.1480 - acc: 0.3077 - val_loss: 1.0883 - val_acc: 0.3889\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.08831, saving model to weights.best.hdf5\n",
            "Epoch 2/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 1.0821 - acc: 0.3894 - val_loss: 1.0829 - val_acc: 0.3889\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.08831 to 1.08295, saving model to weights.best.hdf5\n",
            "Epoch 3/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 1.0833 - acc: 0.3894 - val_loss: 1.0769 - val_acc: 0.3889\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.08295 to 1.07691, saving model to weights.best.hdf5\n",
            "Epoch 4/100\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.0660 - acc: 0.4087 - val_loss: 1.0696 - val_acc: 0.3889\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.07691 to 1.06963, saving model to weights.best.hdf5\n",
            "Epoch 5/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 1.0383 - acc: 0.4519 - val_loss: 1.0659 - val_acc: 0.3889\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.06963 to 1.06586, saving model to weights.best.hdf5\n",
            "Epoch 6/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 1.0596 - acc: 0.3702 - val_loss: 1.0519 - val_acc: 0.3889\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.06586 to 1.05193, saving model to weights.best.hdf5\n",
            "Epoch 7/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 1.0351 - acc: 0.4087 - val_loss: 1.0319 - val_acc: 0.3889\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.05193 to 1.03192, saving model to weights.best.hdf5\n",
            "Epoch 8/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.9899 - acc: 0.4183 - val_loss: 1.0041 - val_acc: 0.3889\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.03192 to 1.00414, saving model to weights.best.hdf5\n",
            "Epoch 9/100\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 0.9367 - acc: 0.4183 - val_loss: 0.9343 - val_acc: 0.3889\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.00414 to 0.93429, saving model to weights.best.hdf5\n",
            "Epoch 10/100\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 0.8517 - acc: 0.4471 - val_loss: 0.8701 - val_acc: 0.4444\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.93429 to 0.87012, saving model to weights.best.hdf5\n",
            "Epoch 11/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.7098 - acc: 0.6154 - val_loss: 0.7221 - val_acc: 0.7444\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.87012 to 0.72214, saving model to weights.best.hdf5\n",
            "Epoch 12/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.5014 - acc: 0.8654 - val_loss: 0.5058 - val_acc: 0.8222\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.72214 to 0.50584, saving model to weights.best.hdf5\n",
            "Epoch 13/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.2709 - acc: 0.9375 - val_loss: 0.4246 - val_acc: 0.8444\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.50584 to 0.42460, saving model to weights.best.hdf5\n",
            "Epoch 14/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.1301 - acc: 0.9760 - val_loss: 0.3836 - val_acc: 0.8556\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.42460 to 0.38356, saving model to weights.best.hdf5\n",
            "Epoch 15/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.1058 - acc: 0.9760 - val_loss: 0.3572 - val_acc: 0.8667\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.38356 to 0.35724, saving model to weights.best.hdf5\n",
            "Epoch 16/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0559 - acc: 0.9808 - val_loss: 0.3190 - val_acc: 0.8889\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.35724 to 0.31902, saving model to weights.best.hdf5\n",
            "Epoch 17/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0393 - acc: 0.9952 - val_loss: 0.3933 - val_acc: 0.8444\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.31902\n",
            "Epoch 18/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0229 - acc: 0.9952 - val_loss: 0.3260 - val_acc: 0.8889\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.31902\n",
            "Epoch 19/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0190 - acc: 0.9952 - val_loss: 0.2669 - val_acc: 0.9333\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.31902 to 0.26691, saving model to weights.best.hdf5\n",
            "Epoch 20/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0278 - acc: 0.9952 - val_loss: 0.2986 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.26691\n",
            "Epoch 21/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0426 - acc: 0.9856 - val_loss: 0.3355 - val_acc: 0.8667\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.26691\n",
            "Epoch 22/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0165 - acc: 1.0000 - val_loss: 0.2768 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.26691\n",
            "Epoch 23/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0152 - acc: 0.9952 - val_loss: 0.3011 - val_acc: 0.8889\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.26691\n",
            "Epoch 24/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0212 - acc: 0.9904 - val_loss: 0.3226 - val_acc: 0.8778\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.26691\n",
            "Epoch 25/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0122 - acc: 1.0000 - val_loss: 0.3251 - val_acc: 0.8889\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.26691\n",
            "Epoch 26/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0165 - acc: 0.9952 - val_loss: 0.3486 - val_acc: 0.8667\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.26691\n",
            "Epoch 27/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0151 - acc: 0.9952 - val_loss: 0.2661 - val_acc: 0.9111\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.26691 to 0.26605, saving model to weights.best.hdf5\n",
            "Epoch 28/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0254 - acc: 0.9904 - val_loss: 0.2523 - val_acc: 0.9111\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.26605 to 0.25231, saving model to weights.best.hdf5\n",
            "Epoch 29/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0217 - acc: 0.9904 - val_loss: 0.4685 - val_acc: 0.8556\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.25231\n",
            "Epoch 30/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0364 - acc: 0.9952 - val_loss: 0.5559 - val_acc: 0.8556\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.25231\n",
            "Epoch 31/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0191 - acc: 0.9952 - val_loss: 0.2775 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.25231\n",
            "Epoch 32/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0271 - acc: 0.9904 - val_loss: 0.2338 - val_acc: 0.9111\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.25231 to 0.23381, saving model to weights.best.hdf5\n",
            "Epoch 33/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0207 - acc: 0.9952 - val_loss: 0.2342 - val_acc: 0.9222\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.23381\n",
            "Epoch 34/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0216 - acc: 0.9952 - val_loss: 0.3965 - val_acc: 0.8556\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.23381\n",
            "Epoch 35/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0200 - acc: 0.9952 - val_loss: 0.3673 - val_acc: 0.8667\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.23381\n",
            "Epoch 36/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0148 - acc: 0.9952 - val_loss: 0.2770 - val_acc: 0.9222\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.23381\n",
            "Epoch 37/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0122 - acc: 0.9952 - val_loss: 0.2567 - val_acc: 0.9333\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.23381\n",
            "Epoch 38/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0129 - acc: 0.9952 - val_loss: 0.2417 - val_acc: 0.9333\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.23381\n",
            "Epoch 39/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0125 - acc: 0.9952 - val_loss: 0.2469 - val_acc: 0.9333\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.23381\n",
            "Epoch 40/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0134 - acc: 0.9952 - val_loss: 0.2630 - val_acc: 0.9333\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.23381\n",
            "Epoch 41/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.9111\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.23381\n",
            "Epoch 42/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0185 - acc: 0.9952 - val_loss: 0.3573 - val_acc: 0.8667\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.23381\n",
            "Epoch 43/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0121 - acc: 0.9952 - val_loss: 0.3305 - val_acc: 0.8778\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.23381\n",
            "Epoch 44/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0209 - acc: 0.9904 - val_loss: 0.3133 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.23381\n",
            "Epoch 45/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.3427 - val_acc: 0.8667\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.23381\n",
            "Epoch 46/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0156 - acc: 0.9904 - val_loss: 0.3034 - val_acc: 0.9111\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.23381\n",
            "Epoch 47/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0133 - acc: 0.9904 - val_loss: 0.3016 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.23381\n",
            "Epoch 48/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0103 - acc: 0.9952 - val_loss: 0.3306 - val_acc: 0.8778\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.23381\n",
            "Epoch 49/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0218 - acc: 0.9952 - val_loss: 0.3228 - val_acc: 0.8778\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.23381\n",
            "Epoch 50/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.2726 - val_acc: 0.9222\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.23381\n",
            "Epoch 51/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0149 - acc: 0.9904 - val_loss: 0.2624 - val_acc: 0.9444\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.23381\n",
            "Epoch 52/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0150 - acc: 0.9952 - val_loss: 0.2498 - val_acc: 0.9444\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.23381\n",
            "Epoch 53/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.2381 - val_acc: 0.9444\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.23381\n",
            "Epoch 54/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0180 - acc: 0.9952 - val_loss: 0.2514 - val_acc: 0.9333\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.23381\n",
            "Epoch 55/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0215 - acc: 0.9952 - val_loss: 0.2918 - val_acc: 0.9222\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.23381\n",
            "Epoch 56/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0098 - acc: 0.9952 - val_loss: 0.3445 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.23381\n",
            "Epoch 57/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.3625 - val_acc: 0.8778\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.23381\n",
            "Epoch 58/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0230 - acc: 0.9952 - val_loss: 0.3710 - val_acc: 0.8667\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.23381\n",
            "Epoch 59/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0104 - acc: 0.9952 - val_loss: 0.3477 - val_acc: 0.8778\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.23381\n",
            "Epoch 60/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0079 - acc: 0.9952 - val_loss: 0.2880 - val_acc: 0.9222\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.23381\n",
            "Epoch 61/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.2579 - val_acc: 0.9444\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.23381\n",
            "Epoch 62/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0141 - acc: 0.9952 - val_loss: 0.2876 - val_acc: 0.9333\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.23381\n",
            "Epoch 63/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0305 - acc: 0.9904 - val_loss: 0.2878 - val_acc: 0.9222\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.23381\n",
            "Epoch 64/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0236 - acc: 0.9904 - val_loss: 0.2918 - val_acc: 0.9222\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.23381\n",
            "Epoch 65/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0205 - acc: 0.9952 - val_loss: 0.3092 - val_acc: 0.9222\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.23381\n",
            "Epoch 66/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0118 - acc: 0.9952 - val_loss: 0.3304 - val_acc: 0.8778\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.23381\n",
            "Epoch 67/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0115 - acc: 0.9952 - val_loss: 0.3298 - val_acc: 0.8778\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.23381\n",
            "Epoch 68/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0133 - acc: 0.9904 - val_loss: 0.2955 - val_acc: 0.9333\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.23381\n",
            "Epoch 69/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0104 - acc: 0.9952 - val_loss: 0.2680 - val_acc: 0.9444\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.23381\n",
            "Epoch 70/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.2484 - val_acc: 0.9444\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.23381\n",
            "Epoch 71/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0070 - acc: 0.9952 - val_loss: 0.2446 - val_acc: 0.9444\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.23381\n",
            "Epoch 72/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.2724 - val_acc: 0.9444\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.23381\n",
            "Epoch 73/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0087 - acc: 0.9952 - val_loss: 0.2725 - val_acc: 0.9444\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.23381\n",
            "Epoch 74/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0088 - acc: 0.9952 - val_loss: 0.2646 - val_acc: 0.9444\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.23381\n",
            "Epoch 75/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0105 - acc: 0.9904 - val_loss: 0.2492 - val_acc: 0.9444\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.23381\n",
            "Epoch 76/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0083 - acc: 0.9952 - val_loss: 0.2403 - val_acc: 0.9444\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.23381\n",
            "Epoch 77/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0092 - acc: 0.9952 - val_loss: 0.2869 - val_acc: 0.9333\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.23381\n",
            "Epoch 78/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0144 - acc: 0.9904 - val_loss: 0.3168 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.23381\n",
            "Epoch 79/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.2966 - val_acc: 0.9111\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.23381\n",
            "Epoch 80/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0074 - acc: 0.9952 - val_loss: 0.2519 - val_acc: 0.9444\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.23381\n",
            "Epoch 81/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.2372 - val_acc: 0.9444\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.23381\n",
            "Epoch 82/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.2391 - val_acc: 0.9444\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.23381\n",
            "Epoch 83/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0075 - acc: 0.9952 - val_loss: 0.2457 - val_acc: 0.9444\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.23381\n",
            "Epoch 84/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.2626 - val_acc: 0.9444\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.23381\n",
            "Epoch 85/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0090 - acc: 0.9952 - val_loss: 0.2843 - val_acc: 0.9444\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.23381\n",
            "Epoch 86/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.3015 - val_acc: 0.9333\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.23381\n",
            "Epoch 87/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0070 - acc: 0.9952 - val_loss: 0.3311 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.23381\n",
            "Epoch 88/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0187 - acc: 0.9904 - val_loss: 0.3010 - val_acc: 0.9222\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.23381\n",
            "Epoch 89/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0059 - acc: 0.9952 - val_loss: 0.3174 - val_acc: 0.9111\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.23381\n",
            "Epoch 90/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0063 - acc: 0.9952 - val_loss: 0.3389 - val_acc: 0.8889\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.23381\n",
            "Epoch 91/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0099 - acc: 0.9952 - val_loss: 0.3321 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.23381\n",
            "Epoch 92/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0122 - acc: 0.9904 - val_loss: 0.3335 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.23381\n",
            "Epoch 93/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0162 - acc: 0.9904 - val_loss: 0.3250 - val_acc: 0.9111\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.23381\n",
            "Epoch 94/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0114 - acc: 0.9952 - val_loss: 0.3071 - val_acc: 0.9333\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.23381\n",
            "Epoch 95/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.2915 - val_acc: 0.9333\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.23381\n",
            "Epoch 96/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0148 - acc: 0.9904 - val_loss: 0.2851 - val_acc: 0.9333\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.23381\n",
            "Epoch 97/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.2803 - val_acc: 0.9444\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.23381\n",
            "Epoch 98/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0089 - acc: 0.9952 - val_loss: 0.2984 - val_acc: 0.9333\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.23381\n",
            "Epoch 99/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.3138 - val_acc: 0.9222\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.23381\n",
            "Epoch 100/100\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.0088 - acc: 0.9904 - val_loss: 0.3152 - val_acc: 0.9222\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.23381\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6e1908fa20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "metadata": {
        "id": "CcjmXiyHt4QG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9a675378-cb34-45e8-cd0c-efcdf2ef00c0"
      },
      "cell_type": "code",
      "source": [
        "model.load_weights(\"weights.best.hdf5\")\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "scores = model.evaluate(test_image, test_y)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "186/186 [==============================] - 0s 995us/step\n",
            "acc: 59.14%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5hpON0pft4QO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2302
        },
        "outputId": "c34ebca5-79c5-4e20-cf2e-d74468eafed4"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " frame0.jpg     frame20.jpg    frame51.jpg   test161.jpg\n",
            " frame100.jpg   frame210.jpg   frame52.jpg   test162.jpg\n",
            " frame101.jpg   frame211.jpg   frame53.jpg   test163.jpg\n",
            " frame102.jpg   frame212.jpg   frame54.jpg   test164.jpg\n",
            " frame103.jpg   frame213.jpg   frame55.jpg   test165.jpg\n",
            " frame104.jpg   frame214.jpg   frame56.jpg   test166.jpg\n",
            " frame105.jpg   frame215.jpg   frame57.jpg   test167.jpg\n",
            " frame106.jpg   frame216.jpg   frame58.jpg   test168.jpg\n",
            " frame107.jpg   frame217.jpg   frame59.jpg   test169.jpg\n",
            " frame108.jpg   frame218.jpg   frame5.jpg    test16.jpg\n",
            " frame109.jpg   frame219.jpg   frame60.jpg   test170.jpg\n",
            " frame10.jpg    frame21.jpg    frame61.jpg   test171.jpg\n",
            " frame110.jpg   frame220.jpg   frame62.jpg   test172.jpg\n",
            " frame111.jpg   frame221.jpg   frame63.jpg   test173.jpg\n",
            " frame112.jpg   frame222.jpg   frame64.jpg   test174.jpg\n",
            " frame113.jpg   frame223.jpg   frame65.jpg   test175.jpg\n",
            " frame114.jpg   frame224.jpg   frame66.jpg   test176.jpg\n",
            " frame115.jpg   frame225.jpg   frame67.jpg   test177.jpg\n",
            " frame116.jpg   frame226.jpg   frame68.jpg   test178.jpg\n",
            " frame117.jpg   frame227.jpg   frame69.jpg   test179.jpg\n",
            " frame118.jpg   frame228.jpg   frame6.jpg    test17.jpg\n",
            " frame119.jpg   frame229.jpg   frame70.jpg   test180.jpg\n",
            " frame11.jpg    frame22.jpg    frame71.jpg   test181.jpg\n",
            " frame120.jpg   frame230.jpg   frame72.jpg   test182.jpg\n",
            " frame121.jpg   frame231.jpg   frame73.jpg   test183.jpg\n",
            " frame122.jpg   frame232.jpg   frame74.jpg   test184.jpg\n",
            " frame123.jpg   frame233.jpg   frame75.jpg   test185.jpg\n",
            " frame124.jpg   frame234.jpg   frame76.jpg   test18.jpg\n",
            " frame125.jpg   frame235.jpg   frame77.jpg   test19.jpg\n",
            " frame126.jpg   frame236.jpg   frame78.jpg   test1.jpg\n",
            " frame127.jpg   frame237.jpg   frame79.jpg   test20.jpg\n",
            " frame128.jpg   frame238.jpg   frame7.jpg    test21.jpg\n",
            " frame129.jpg   frame239.jpg   frame80.jpg   test22.jpg\n",
            " frame12.jpg    frame23.jpg    frame81.jpg   test23.jpg\n",
            " frame130.jpg   frame240.jpg   frame82.jpg   test24.jpg\n",
            " frame131.jpg   frame241.jpg   frame83.jpg   test25.jpg\n",
            " frame132.jpg   frame242.jpg   frame84.jpg   test26.jpg\n",
            " frame133.jpg   frame243.jpg   frame85.jpg   test27.jpg\n",
            " frame134.jpg   frame244.jpg   frame86.jpg   test28.jpg\n",
            " frame135.jpg   frame245.jpg   frame87.jpg   test29.jpg\n",
            " frame136.jpg   frame246.jpg   frame88.jpg   test2.jpg\n",
            " frame137.jpg   frame247.jpg   frame89.jpg   test30.jpg\n",
            " frame138.jpg   frame248.jpg   frame8.jpg    test31.jpg\n",
            " frame139.jpg   frame249.jpg   frame90.jpg   test32.jpg\n",
            " frame13.jpg    frame24.jpg    frame91.jpg   test33.jpg\n",
            " frame140.jpg   frame250.jpg   frame92.jpg   test34.jpg\n",
            " frame141.jpg   frame251.jpg   frame93.jpg   test35.jpg\n",
            " frame142.jpg   frame252.jpg   frame94.jpg   test36.jpg\n",
            " frame143.jpg   frame253.jpg   frame95.jpg   test37.jpg\n",
            " frame144.jpg   frame254.jpg   frame96.jpg   test38.jpg\n",
            " frame145.jpg   frame255.jpg   frame97.jpg   test39.jpg\n",
            " frame146.jpg   frame256.jpg   frame98.jpg   test3.jpg\n",
            " frame147.jpg   frame257.jpg   frame99.jpg   test40.jpg\n",
            " frame148.jpg   frame258.jpg   frame9.jpg    test41.jpg\n",
            " frame149.jpg   frame259.jpg   test0.jpg     test42.jpg\n",
            " frame14.jpg    frame25.jpg    test100.jpg   test43.jpg\n",
            " frame150.jpg   frame260.jpg   test101.jpg   test44.jpg\n",
            " frame151.jpg   frame261.jpg   test102.jpg   test45.jpg\n",
            " frame152.jpg   frame262.jpg   test103.jpg   test46.jpg\n",
            " frame153.jpg   frame263.jpg   test104.jpg   test47.jpg\n",
            " frame154.jpg   frame264.jpg   test105.jpg   test48.jpg\n",
            " frame155.jpg   frame265.jpg   test106.jpg   test49.jpg\n",
            " frame156.jpg   frame266.jpg   test107.jpg   test4.jpg\n",
            " frame157.jpg   frame267.jpg   test108.jpg   test50.jpg\n",
            " frame158.jpg   frame268.jpg   test109.jpg   test51.jpg\n",
            " frame159.jpg   frame269.jpg   test10.jpg    test52.jpg\n",
            " frame15.jpg    frame26.jpg    test110.jpg   test53.jpg\n",
            " frame160.jpg   frame270.jpg   test111.jpg   test54.jpg\n",
            " frame161.jpg   frame271.jpg   test112.jpg   test55.jpg\n",
            " frame162.jpg   frame272.jpg   test113.jpg   test56.jpg\n",
            " frame163.jpg   frame273.jpg   test114.jpg   test57.jpg\n",
            " frame164.jpg   frame274.jpg   test115.jpg   test58.jpg\n",
            " frame165.jpg   frame275.jpg   test116.jpg   test59.jpg\n",
            " frame166.jpg   frame276.jpg   test117.jpg   test5.jpg\n",
            " frame167.jpg   frame277.jpg   test118.jpg   test60.jpg\n",
            " frame168.jpg   frame278.jpg   test119.jpg   test61.jpg\n",
            " frame169.jpg   frame279.jpg   test11.jpg    test62.jpg\n",
            " frame16.jpg    frame27.jpg    test120.jpg   test63.jpg\n",
            " frame170.jpg   frame280.jpg   test121.jpg   test64.jpg\n",
            " frame171.jpg   frame281.jpg   test122.jpg   test65.jpg\n",
            " frame172.jpg   frame282.jpg   test123.jpg   test66.jpg\n",
            " frame173.jpg   frame283.jpg   test124.jpg   test67.jpg\n",
            " frame174.jpg   frame284.jpg   test125.jpg   test68.jpg\n",
            " frame175.jpg   frame285.jpg   test126.jpg   test69.jpg\n",
            " frame176.jpg   frame286.jpg   test127.jpg   test6.jpg\n",
            " frame177.jpg   frame287.jpg   test128.jpg   test70.jpg\n",
            " frame178.jpg   frame288.jpg   test129.jpg   test71.jpg\n",
            " frame179.jpg   frame289.jpg   test12.jpg    test72.jpg\n",
            " frame17.jpg    frame28.jpg    test130.jpg   test73.jpg\n",
            " frame180.jpg   frame290.jpg   test131.jpg   test74.jpg\n",
            " frame181.jpg   frame291.jpg   test132.jpg   test75.jpg\n",
            " frame182.jpg   frame292.jpg   test133.jpg   test76.jpg\n",
            " frame183.jpg   frame293.jpg   test134.jpg   test77.jpg\n",
            " frame184.jpg   frame294.jpg   test135.jpg   test78.jpg\n",
            " frame185.jpg   frame295.jpg   test136.jpg   test79.jpg\n",
            " frame186.jpg   frame296.jpg   test137.jpg   test7.jpg\n",
            " frame187.jpg   frame297.jpg   test138.jpg   test80.jpg\n",
            " frame188.jpg   frame29.jpg    test139.jpg   test81.jpg\n",
            " frame189.jpg   frame2.jpg     test13.jpg    test82.jpg\n",
            " frame18.jpg    frame30.jpg    test140.jpg   test83.jpg\n",
            " frame190.jpg   frame31.jpg    test141.jpg   test84.jpg\n",
            " frame191.jpg   frame32.jpg    test142.jpg   test85.jpg\n",
            " frame192.jpg   frame33.jpg    test143.jpg   test86.jpg\n",
            " frame193.jpg   frame34.jpg    test144.jpg   test87.jpg\n",
            " frame194.jpg   frame35.jpg    test145.jpg   test88.jpg\n",
            " frame195.jpg   frame36.jpg    test146.jpg   test89.jpg\n",
            " frame196.jpg   frame37.jpg    test147.jpg   test8.jpg\n",
            " frame197.jpg   frame38.jpg    test148.jpg   test90.jpg\n",
            " frame198.jpg   frame39.jpg    test149.jpg   test91.jpg\n",
            " frame199.jpg   frame3.jpg     test14.jpg    test92.jpg\n",
            " frame19.jpg    frame40.jpg    test150.jpg   test93.jpg\n",
            " frame1.jpg     frame41.jpg    test151.jpg   test94.jpg\n",
            " frame200.jpg   frame42.jpg    test152.jpg   test95.jpg\n",
            " frame201.jpg   frame43.jpg    test153.jpg   test96.jpg\n",
            " frame202.jpg   frame44.jpg    test154.jpg   test97.jpg\n",
            " frame203.jpg   frame45.jpg    test155.jpg   test98.jpg\n",
            " frame204.jpg   frame46.jpg    test156.jpg   test99.jpg\n",
            " frame205.jpg   frame47.jpg    test157.jpg   test9.jpg\n",
            " frame206.jpg   frame48.jpg    test158.jpg  'Tom and Jerry 3.mp4'\n",
            " frame207.jpg   frame49.jpg    test159.jpg  'Tom and jerry.mp4'\n",
            " frame208.jpg   frame4.jpg     test15.jpg    weights.best.hdf5\n",
            " frame209.jpg   frame50.jpg    test160.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ne5FoLRWt4QW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}